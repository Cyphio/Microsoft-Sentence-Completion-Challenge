Beginning training
C:\Users\harry\Anaconda3\envs\ML38\lib\site-packages\torch\nn\modules\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Epoch 01: | Train Loss: 4.65842
Epoch 02: | Train Loss: 4.53423
Epoch 03: | Train Loss: 4.41451
Epoch 04: | Train Loss: 4.29750
Epoch 05: | Train Loss: 4.18264
Epoch 06: | Train Loss: 4.06818
Epoch 07: | Train Loss: 3.95328
Epoch 08: | Train Loss: 3.83741
Epoch 09: | Train Loss: 3.71962
Epoch 10: | Train Loss: 3.60077
Epoch 11: | Train Loss: 3.48092
Epoch 12: | Train Loss: 3.35993
Epoch 13: | Train Loss: 3.23884
Epoch 14: | Train Loss: 3.11834
Epoch 15: | Train Loss: 2.99923
Epoch 16: | Train Loss: 2.88185
Epoch 17: | Train Loss: 2.76666
Epoch 18: | Train Loss: 2.65347
Epoch 19: | Train Loss: 2.54155
Epoch 20: | Train Loss: 2.43099
Epoch 21: | Train Loss: 2.32154
Epoch 22: | Train Loss: 2.21362
Epoch 23: | Train Loss: 2.10645
Epoch 24: | Train Loss: 2.00148
Epoch 25: | Train Loss: 1.89821
Epoch 26: | Train Loss: 1.79698
Epoch 27: | Train Loss: 1.69818
Epoch 28: | Train Loss: 1.60235
Epoch 29: | Train Loss: 1.50923
Epoch 30: | Train Loss: 1.41891
Epoch 31: | Train Loss: 1.33169
Epoch 32: | Train Loss: 1.24817
Epoch 33: | Train Loss: 1.16779
Epoch 34: | Train Loss: 1.09113
Epoch 35: | Train Loss: 1.01820
Epoch 36: | Train Loss: 0.94921
Epoch 37: | Train Loss: 0.88415
Epoch 38: | Train Loss: 0.82317
Epoch 39: | Train Loss: 0.76578
Epoch 40: | Train Loss: 0.71262
Epoch 41: | Train Loss: 0.66297
Epoch 42: | Train Loss: 0.61702
Epoch 43: | Train Loss: 0.57479
Epoch 44: | Train Loss: 0.53568
Epoch 45: | Train Loss: 0.49991
Epoch 46: | Train Loss: 0.46685
Epoch 47: | Train Loss: 0.43675
Epoch 48: | Train Loss: 0.40903
Epoch 49: | Train Loss: 0.38368
Epoch 50: | Train Loss: 0.36055
Epoch 51: | Train Loss: 0.33928
Epoch 52: | Train Loss: 0.31985
Epoch 53: | Train Loss: 0.30197
Epoch 54: | Train Loss: 0.28561
Epoch 55: | Train Loss: 0.27058
Epoch 56: | Train Loss: 0.25676
Epoch 57: | Train Loss: 0.24399
Epoch 58: | Train Loss: 0.23223
Epoch 59: | Train Loss: 0.22139
Epoch 60: | Train Loss: 0.21134
Epoch 61: | Train Loss: 0.20203
Epoch 62: | Train Loss: 0.19338
Epoch 63: | Train Loss: 0.18535
Epoch 64: | Train Loss: 0.17787
Epoch 65: | Train Loss: 0.17088
Epoch 66: | Train Loss: 0.16435
Epoch 67: | Train Loss: 0.15825
Epoch 68: | Train Loss: 0.15253
Epoch 69: | Train Loss: 0.14716
Epoch 70: | Train Loss: 0.14210
Epoch 71: | Train Loss: 0.13736
Epoch 72: | Train Loss: 0.13288
Epoch 73: | Train Loss: 0.12864
Epoch 74: | Train Loss: 0.12466
Epoch 75: | Train Loss: 0.12087
Epoch 76: | Train Loss: 0.11729
Epoch 77: | Train Loss: 0.11389
Epoch 78: | Train Loss: 0.11067
Epoch 79: | Train Loss: 0.10759
Epoch 80: | Train Loss: 0.10468
Epoch 81: | Train Loss: 0.10190
Epoch 82: | Train Loss: 0.09926
Epoch 83: | Train Loss: 0.09672
Epoch 84: | Train Loss: 0.09431
Epoch 85: | Train Loss: 0.09201
Epoch 86: | Train Loss: 0.08980
Epoch 87: | Train Loss: 0.08770
Epoch 88: | Train Loss: 0.08566
Epoch 89: | Train Loss: 0.08373
Epoch 90: | Train Loss: 0.08187
Epoch 91: | Train Loss: 0.08008
Epoch 92: | Train Loss: 0.07836
Epoch 93: | Train Loss: 0.07671
Epoch 94: | Train Loss: 0.07512
Epoch 95: | Train Loss: 0.07358
Epoch 96: | Train Loss: 0.07210
Epoch 97: | Train Loss: 0.07069
Epoch 98: | Train Loss: 0.06931
Epoch 99: | Train Loss: 0.06799
Epoch 100: | Train Loss: 0.06670
Finished Training

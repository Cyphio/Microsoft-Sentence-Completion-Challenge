Beginning training
C:\Users\harry\Anaconda3\envs\ML38\lib\site-packages\torch\nn\modules\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Epoch 01: | Train Loss: 2.83321
Epoch 02: | Train Loss: 2.78135
Epoch 03: | Train Loss: 2.73300
Epoch 04: | Train Loss: 2.68679
Epoch 05: | Train Loss: 2.64199
Epoch 06: | Train Loss: 2.59828
Epoch 07: | Train Loss: 2.55558
Epoch 08: | Train Loss: 2.51391
Epoch 09: | Train Loss: 2.47331
Epoch 10: | Train Loss: 2.43389
Epoch 11: | Train Loss: 2.39569
Epoch 12: | Train Loss: 2.35863
Epoch 13: | Train Loss: 2.32237
Epoch 14: | Train Loss: 2.28633
Epoch 15: | Train Loss: 2.24978
Epoch 16: | Train Loss: 2.21209
Epoch 17: | Train Loss: 2.17295
Epoch 18: | Train Loss: 2.13239
Epoch 19: | Train Loss: 2.09071
Epoch 20: | Train Loss: 2.04832
Epoch 21: | Train Loss: 2.00558
Epoch 22: | Train Loss: 1.96275
Epoch 23: | Train Loss: 1.91988
Epoch 24: | Train Loss: 1.87684
Epoch 25: | Train Loss: 1.83343
Epoch 26: | Train Loss: 1.78970
Epoch 27: | Train Loss: 1.74590
Epoch 28: | Train Loss: 1.70216
Epoch 29: | Train Loss: 1.65826
Epoch 30: | Train Loss: 1.61389
Epoch 31: | Train Loss: 1.56910
Epoch 32: | Train Loss: 1.52442
Epoch 33: | Train Loss: 1.48018
Epoch 34: | Train Loss: 1.43615
Epoch 35: | Train Loss: 1.39201
Epoch 36: | Train Loss: 1.34792
Epoch 37: | Train Loss: 1.30432
Epoch 38: | Train Loss: 1.26155
Epoch 39: | Train Loss: 1.21965
Epoch 40: | Train Loss: 1.17830
Epoch 41: | Train Loss: 1.13737
Epoch 42: | Train Loss: 1.09717
Epoch 43: | Train Loss: 1.05830
Epoch 44: | Train Loss: 1.02106
Epoch 45: | Train Loss: 0.98509
Epoch 46: | Train Loss: 0.94986
Epoch 47: | Train Loss: 0.91525
Epoch 48: | Train Loss: 0.88118
Epoch 49: | Train Loss: 0.84753
Epoch 50: | Train Loss: 0.81461
Epoch 51: | Train Loss: 0.78276
Epoch 52: | Train Loss: 0.75190
Epoch 53: | Train Loss: 0.72200
Epoch 54: | Train Loss: 0.69324
Epoch 55: | Train Loss: 0.66561
Epoch 56: | Train Loss: 0.63904
Epoch 57: | Train Loss: 0.61362
Epoch 58: | Train Loss: 0.58938
Epoch 59: | Train Loss: 0.56637
Epoch 60: | Train Loss: 0.54568
Epoch 61: | Train Loss: 0.52500
Epoch 62: | Train Loss: 0.50423
Epoch 63: | Train Loss: 0.48324
Epoch 64: | Train Loss: 0.46770
Epoch 65: | Train Loss: 0.44853
Epoch 66: | Train Loss: 0.43238
Epoch 67: | Train Loss: 0.41567
Epoch 68: | Train Loss: 0.40091
Epoch 69: | Train Loss: 0.38591
Epoch 70: | Train Loss: 0.37270
Epoch 71: | Train Loss: 0.35841
Epoch 72: | Train Loss: 0.34695
Epoch 73: | Train Loss: 0.33389
Epoch 74: | Train Loss: 0.32309
Epoch 75: | Train Loss: 0.31201
Epoch 76: | Train Loss: 0.30133
Epoch 77: | Train Loss: 0.29192
Epoch 78: | Train Loss: 0.28201
Epoch 79: | Train Loss: 0.27315
Epoch 80: | Train Loss: 0.26474
Epoch 81: | Train Loss: 0.25630
Epoch 82: | Train Loss: 0.24863
Epoch 83: | Train Loss: 0.24130
Epoch 84: | Train Loss: 0.23402
Epoch 85: | Train Loss: 0.22732
Epoch 86: | Train Loss: 0.22095
Epoch 87: | Train Loss: 0.21467
Epoch 88: | Train Loss: 0.20878
Epoch 89: | Train Loss: 0.20326
Epoch 90: | Train Loss: 0.19785
Epoch 91: | Train Loss: 0.19268
Epoch 92: | Train Loss: 0.18785
Epoch 93: | Train Loss: 0.18319
Epoch 94: | Train Loss: 0.17868
Epoch 95: | Train Loss: 0.17443
Epoch 96: | Train Loss: 0.17038
Epoch 97: | Train Loss: 0.16646
Epoch 98: | Train Loss: 0.16270
Epoch 99: | Train Loss: 0.15914
Epoch 100: | Train Loss: 0.15572
Finished Training

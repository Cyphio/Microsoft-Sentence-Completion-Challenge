Beginning training
C:\Users\harry\Anaconda3\envs\ML38\lib\site-packages\torch\nn\modules\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Epoch 01: | Train Loss: 2.82747
Epoch 02: | Train Loss: 2.76781
Epoch 03: | Train Loss: 2.71220
Epoch 04: | Train Loss: 2.66001
Epoch 05: | Train Loss: 2.61108
Epoch 06: | Train Loss: 2.56519
Epoch 07: | Train Loss: 2.52274
Epoch 08: | Train Loss: 2.48455
Epoch 09: | Train Loss: 2.45109
Epoch 10: | Train Loss: 2.42216
Epoch 11: | Train Loss: 2.39693
Epoch 12: | Train Loss: 2.37414
Epoch 13: | Train Loss: 2.35246
Epoch 14: | Train Loss: 2.33076
Epoch 15: | Train Loss: 2.30825
Epoch 16: | Train Loss: 2.28446
Epoch 17: | Train Loss: 2.25917
Epoch 18: | Train Loss: 2.23231
Epoch 19: | Train Loss: 2.20386
Epoch 20: | Train Loss: 2.17382
Epoch 21: | Train Loss: 2.14232
Epoch 22: | Train Loss: 2.10958
Epoch 23: | Train Loss: 2.07586
Epoch 24: | Train Loss: 2.04137
Epoch 25: | Train Loss: 2.00621
Epoch 26: | Train Loss: 1.97042
Epoch 27: | Train Loss: 1.93401
Epoch 28: | Train Loss: 1.89698
Epoch 29: | Train Loss: 1.85937
Epoch 30: | Train Loss: 1.82130
Epoch 31: | Train Loss: 1.78303
Epoch 32: | Train Loss: 1.74494
Epoch 33: | Train Loss: 1.70745
Epoch 34: | Train Loss: 1.67069
Epoch 35: | Train Loss: 1.63444
Epoch 36: | Train Loss: 1.59827
Epoch 37: | Train Loss: 1.56181
Epoch 38: | Train Loss: 1.52485
Epoch 39: | Train Loss: 1.48743
Epoch 40: | Train Loss: 1.44977
Epoch 41: | Train Loss: 1.41219
Epoch 42: | Train Loss: 1.37494
Epoch 43: | Train Loss: 1.33817
Epoch 44: | Train Loss: 1.30195
Epoch 45: | Train Loss: 1.26628
Epoch 46: | Train Loss: 1.23104
Epoch 47: | Train Loss: 1.19617
Epoch 48: | Train Loss: 1.16176
Epoch 49: | Train Loss: 1.12798
Epoch 50: | Train Loss: 1.09497
Epoch 51: | Train Loss: 1.06264
Epoch 52: | Train Loss: 1.03084
Epoch 53: | Train Loss: 0.99947
Epoch 54: | Train Loss: 0.96855
Epoch 55: | Train Loss: 0.93820
Epoch 56: | Train Loss: 0.90849
Epoch 57: | Train Loss: 0.87948
Epoch 58: | Train Loss: 0.85119
Epoch 59: | Train Loss: 0.82362
Epoch 60: | Train Loss: 0.79682
Epoch 61: | Train Loss: 0.77082
Epoch 62: | Train Loss: 0.74565
Epoch 63: | Train Loss: 0.72128
Epoch 64: | Train Loss: 0.69772
Epoch 65: | Train Loss: 0.67492
Epoch 66: | Train Loss: 0.65282
Epoch 67: | Train Loss: 0.63138
Epoch 68: | Train Loss: 0.61057
Epoch 69: | Train Loss: 0.59040
Epoch 70: | Train Loss: 0.57089
Epoch 71: | Train Loss: 0.55198
Epoch 72: | Train Loss: 0.53363
Epoch 73: | Train Loss: 0.51582
Epoch 74: | Train Loss: 0.49857
Epoch 75: | Train Loss: 0.48191
Epoch 76: | Train Loss: 0.46585
Epoch 77: | Train Loss: 0.45039
Epoch 78: | Train Loss: 0.43554
Epoch 79: | Train Loss: 0.42131
Epoch 80: | Train Loss: 0.40769
Epoch 81: | Train Loss: 0.39464
Epoch 82: | Train Loss: 0.38213
Epoch 83: | Train Loss: 0.37011
Epoch 84: | Train Loss: 0.35856
Epoch 85: | Train Loss: 0.34747
Epoch 86: | Train Loss: 0.33683
Epoch 87: | Train Loss: 0.32663
Epoch 88: | Train Loss: 0.31685
Epoch 89: | Train Loss: 0.30748
Epoch 90: | Train Loss: 0.29849
Epoch 91: | Train Loss: 0.28989
Epoch 92: | Train Loss: 0.28165
Epoch 93: | Train Loss: 0.27378
Epoch 94: | Train Loss: 0.26623
Epoch 95: | Train Loss: 0.25899
Epoch 96: | Train Loss: 0.25203
Epoch 97: | Train Loss: 0.24534
Epoch 98: | Train Loss: 0.23890
Epoch 99: | Train Loss: 0.23270
Epoch 100: | Train Loss: 0.22675
Finished Training

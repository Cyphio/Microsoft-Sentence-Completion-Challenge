Beginning training
C:\Users\harry\Anaconda3\envs\ML38\lib\site-packages\torch\nn\modules\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Epoch 01: | Train Loss: 4.64968
Epoch 02: | Train Loss: 4.61591
Epoch 03: | Train Loss: 4.58252
Epoch 04: | Train Loss: 4.54947
Epoch 05: | Train Loss: 4.51671
Epoch 06: | Train Loss: 4.48423
Epoch 07: | Train Loss: 4.45200
Epoch 08: | Train Loss: 4.42005
Epoch 09: | Train Loss: 4.38833
Epoch 10: | Train Loss: 4.35684
Epoch 11: | Train Loss: 4.32556
Epoch 12: | Train Loss: 4.29450
Epoch 13: | Train Loss: 4.26364
Epoch 14: | Train Loss: 4.23299
Epoch 15: | Train Loss: 4.20251
Epoch 16: | Train Loss: 4.17222
Epoch 17: | Train Loss: 4.14210
Epoch 18: | Train Loss: 4.11213
Epoch 19: | Train Loss: 4.08236
Epoch 20: | Train Loss: 4.05275
Epoch 21: | Train Loss: 4.02328
Epoch 22: | Train Loss: 3.99395
Epoch 23: | Train Loss: 3.96474
Epoch 24: | Train Loss: 3.93565
Epoch 25: | Train Loss: 3.90669
Epoch 26: | Train Loss: 3.87780
Epoch 27: | Train Loss: 3.84898
Epoch 28: | Train Loss: 3.82025
Epoch 29: | Train Loss: 3.79160
Epoch 30: | Train Loss: 3.76299
Epoch 31: | Train Loss: 3.73444
Epoch 32: | Train Loss: 3.70593
Epoch 33: | Train Loss: 3.67745
Epoch 34: | Train Loss: 3.64901
Epoch 35: | Train Loss: 3.62059
Epoch 36: | Train Loss: 3.59221
Epoch 37: | Train Loss: 3.56382
Epoch 38: | Train Loss: 3.53543
Epoch 39: | Train Loss: 3.50698
Epoch 40: | Train Loss: 3.47850
Epoch 41: | Train Loss: 3.44997
Epoch 42: | Train Loss: 3.42139
Epoch 43: | Train Loss: 3.39275
Epoch 44: | Train Loss: 3.36407
Epoch 45: | Train Loss: 3.33534
Epoch 46: | Train Loss: 3.30654
Epoch 47: | Train Loss: 3.27769
Epoch 48: | Train Loss: 3.24880
Epoch 49: | Train Loss: 3.21984
Epoch 50: | Train Loss: 3.19084
Epoch 51: | Train Loss: 3.16178
Epoch 52: | Train Loss: 3.13266
Epoch 53: | Train Loss: 3.10348
Epoch 54: | Train Loss: 3.07426
Epoch 55: | Train Loss: 3.04499
Epoch 56: | Train Loss: 3.01564
Epoch 57: | Train Loss: 2.98625
Epoch 58: | Train Loss: 2.95681
Epoch 59: | Train Loss: 2.92734
Epoch 60: | Train Loss: 2.89780
Epoch 61: | Train Loss: 2.86826
Epoch 62: | Train Loss: 2.83868
Epoch 63: | Train Loss: 2.80905
Epoch 64: | Train Loss: 2.77938
Epoch 65: | Train Loss: 2.74965
Epoch 66: | Train Loss: 2.71988
Epoch 67: | Train Loss: 2.69010
Epoch 68: | Train Loss: 2.66029
Epoch 69: | Train Loss: 2.63045
Epoch 70: | Train Loss: 2.60058
Epoch 71: | Train Loss: 2.57067
Epoch 72: | Train Loss: 2.54080
Epoch 73: | Train Loss: 2.51089
Epoch 74: | Train Loss: 2.48097
Epoch 75: | Train Loss: 2.45107
Epoch 76: | Train Loss: 2.42114
Epoch 77: | Train Loss: 2.39123
Epoch 78: | Train Loss: 2.36137
Epoch 79: | Train Loss: 2.33151
Epoch 80: | Train Loss: 2.30169
Epoch 81: | Train Loss: 2.27193
Epoch 82: | Train Loss: 2.24219
Epoch 83: | Train Loss: 2.21251
Epoch 84: | Train Loss: 2.18288
Epoch 85: | Train Loss: 2.15335
Epoch 86: | Train Loss: 2.12386
Epoch 87: | Train Loss: 2.09445
Epoch 88: | Train Loss: 2.06516
Epoch 89: | Train Loss: 2.03595
Epoch 90: | Train Loss: 2.00686
Epoch 91: | Train Loss: 1.97787
Epoch 92: | Train Loss: 1.94900
Epoch 93: | Train Loss: 1.92025
Epoch 94: | Train Loss: 1.89165
Epoch 95: | Train Loss: 1.86317
Epoch 96: | Train Loss: 1.83487
Epoch 97: | Train Loss: 1.80668
Epoch 98: | Train Loss: 1.77870
Epoch 99: | Train Loss: 1.75086
Epoch 100: | Train Loss: 1.72322
Finished Training

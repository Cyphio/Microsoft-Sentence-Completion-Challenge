Beginning training
C:\Users\harry\Anaconda3\envs\ML38\lib\site-packages\torch\nn\modules\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Epoch 01: | Train Loss: 4.61543
Epoch 02: | Train Loss: 3.75682
Epoch 03: | Train Loss: 3.05158
Epoch 04: | Train Loss: 2.39324
Epoch 05: | Train Loss: 1.77716
Epoch 06: | Train Loss: 1.25215
Epoch 07: | Train Loss: 0.85502
Epoch 08: | Train Loss: 0.58329
Epoch 09: | Train Loss: 0.40996
Epoch 10: | Train Loss: 0.30067
Epoch 11: | Train Loss: 0.22990
Epoch 12: | Train Loss: 0.18267
Epoch 13: | Train Loss: 0.14956
Epoch 14: | Train Loss: 0.12573
Epoch 15: | Train Loss: 0.10797
Epoch 16: | Train Loss: 0.09428
Epoch 17: | Train Loss: 0.08351
Epoch 18: | Train Loss: 0.07482
Epoch 19: | Train Loss: 0.06771
Epoch 20: | Train Loss: 0.06175
Epoch 21: | Train Loss: 0.05673
Epoch 22: | Train Loss: 0.05244
Epoch 23: | Train Loss: 0.04872
Epoch 24: | Train Loss: 0.04548
Epoch 25: | Train Loss: 0.04262
Epoch 26: | Train Loss: 0.04009
Epoch 27: | Train Loss: 0.03783
Epoch 28: | Train Loss: 0.03580
Epoch 29: | Train Loss: 0.03397
Epoch 30: | Train Loss: 0.03231
Epoch 31: | Train Loss: 0.03080
Epoch 32: | Train Loss: 0.02941
Epoch 33: | Train Loss: 0.02815
Epoch 34: | Train Loss: 0.02698
Epoch 35: | Train Loss: 0.02590
Epoch 36: | Train Loss: 0.02490
Epoch 37: | Train Loss: 0.02397
Epoch 38: | Train Loss: 0.02311
Epoch 39: | Train Loss: 0.02230
Epoch 40: | Train Loss: 0.02154
Epoch 41: | Train Loss: 0.02084
Epoch 42: | Train Loss: 0.02017
Epoch 43: | Train Loss: 0.01955
Epoch 44: | Train Loss: 0.01896
Epoch 45: | Train Loss: 0.01840
Epoch 46: | Train Loss: 0.01788
Epoch 47: | Train Loss: 0.01738
Epoch 48: | Train Loss: 0.01691
Epoch 49: | Train Loss: 0.01646
Epoch 50: | Train Loss: 0.01604
Epoch 51: | Train Loss: 0.01563
Epoch 52: | Train Loss: 0.01525
Epoch 53: | Train Loss: 0.01488
Epoch 54: | Train Loss: 0.01453
Epoch 55: | Train Loss: 0.01419
Epoch 56: | Train Loss: 0.01387
Epoch 57: | Train Loss: 0.01356
Epoch 58: | Train Loss: 0.01327
Epoch 59: | Train Loss: 0.01299
Epoch 60: | Train Loss: 0.01272
Epoch 61: | Train Loss: 0.01246
Epoch 62: | Train Loss: 0.01221
Epoch 63: | Train Loss: 0.01197
Epoch 64: | Train Loss: 0.01173
Epoch 65: | Train Loss: 0.01151
Epoch 66: | Train Loss: 0.01130
Epoch 67: | Train Loss: 0.01109
Epoch 68: | Train Loss: 0.01089
Epoch 69: | Train Loss: 0.01069
Epoch 70: | Train Loss: 0.01051
Epoch 71: | Train Loss: 0.01033
Epoch 72: | Train Loss: 0.01015
Epoch 73: | Train Loss: 0.00998
Epoch 74: | Train Loss: 0.00982
Epoch 75: | Train Loss: 0.00966
Epoch 76: | Train Loss: 0.00951
Epoch 77: | Train Loss: 0.00936
Epoch 78: | Train Loss: 0.00921
Epoch 79: | Train Loss: 0.00907
Epoch 80: | Train Loss: 0.00893
Epoch 81: | Train Loss: 0.00880
Epoch 82: | Train Loss: 0.00867
Epoch 83: | Train Loss: 0.00855
Epoch 84: | Train Loss: 0.00843
Epoch 85: | Train Loss: 0.00831
Epoch 86: | Train Loss: 0.00819
Epoch 87: | Train Loss: 0.00808
Epoch 88: | Train Loss: 0.00797
Epoch 89: | Train Loss: 0.00786
Epoch 90: | Train Loss: 0.00776
Epoch 91: | Train Loss: 0.00766
Epoch 92: | Train Loss: 0.00756
Epoch 93: | Train Loss: 0.00746
Epoch 94: | Train Loss: 0.00737
Epoch 95: | Train Loss: 0.00728
Epoch 96: | Train Loss: 0.00719
Epoch 97: | Train Loss: 0.00710
Epoch 98: | Train Loss: 0.00702
Epoch 99: | Train Loss: 0.00693
Epoch 100: | Train Loss: 0.00685
Finished Training
